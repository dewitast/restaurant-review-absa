{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1921\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "file = pd.read_csv(\"reviews.csv\")\n",
    "\n",
    "reviews = file['reviews'].values.tolist()\n",
    "foods = file['food'].values.tolist()\n",
    "services = file['service'].values.tolist()\n",
    "prices = file['price'].values.tolist()\n",
    "places = file['place'].values.tolist()\n",
    "\n",
    "tokenize_reviews = []\n",
    "for review in reviews:\n",
    "    word_tokens = word_tokenize(review)\n",
    "    tokenize_reviews.append(word_tokens)\n",
    "    \n",
    "stoplist = set(stopwords.words('english'))\n",
    "filtered_reviews = []\n",
    "words = []\n",
    "\n",
    "def RemovePunctAndStopWords(tokens):\n",
    "    nonPunct = re.compile('.*[A-Za-z0-9].*')  # must contain a letter or digit\n",
    "    filtered = [w for w in tokens if nonPunct.match(w)]\n",
    "    #Remove the stopwords from filtered text\n",
    "    filtered_words = [word for word in filtered if word.lower() not in stoplist]\n",
    "    frequent_words=['the','and','of','this','am','etc','also','are','were','was','is']\n",
    "    filtered_words = [word for word in filtered_words if word.lower() not in frequent_words]\n",
    "    filtered_words=[word.lower() for word in filtered_words]\n",
    "    return filtered_words\n",
    "\n",
    "for review in tokenize_reviews:\n",
    "    review = RemovePunctAndStopWords(review)\n",
    "    filtered_reviews.append(review)\n",
    "\n",
    "def ngram_list(word_list, n):\n",
    "    all_ngrams = list(ngrams(word_list, n))\n",
    "    ngram_res = []\n",
    "    for ngram in all_ngrams:\n",
    "        ngram_res.append(ngram)\n",
    "    return ngram_res\n",
    "\n",
    "trigram_result = []\n",
    "# for i in range(len(filtered_reviews)):\n",
    "#     if (len(filtered_reviews[i]) > 2):\n",
    "#         trigram = ngram_list(filtered_reviews[i], 3)\n",
    "#         trigram_result.append(dict(Counter(trigram)))\n",
    "\n",
    "for i in range(len(filtered_reviews)):\n",
    "    unigram = ngram_list(filtered_reviews[i], 1)\n",
    "    trigram_result.append(dict(Counter(unigram)))\n",
    "#     bigram = {}\n",
    "#     if (len(filtered_reviews[i]) > 1):\n",
    "#         bigram = ngram_list(filtered_reviews[i], 2)\n",
    "#     trigram_result.append({**dict(Counter(unigram)), **dict(Counter(bigram))})\n",
    "\n",
    "trigram_set = set()\n",
    "trigram_list = []\n",
    "for trigram in trigram_result:\n",
    "    for key in trigram:\n",
    "        trigram_set.add(key)\n",
    "        if key not in trigram_list:\n",
    "            trigram_list.append(key)\n",
    "        \n",
    "pickle.dump(trigram_list, open('trigram.pkl', 'wb'))\n",
    "\n",
    "output_feature = pd.DataFrame(0, columns = trigram_list, index = [i for i in range(len(filtered_reviews))])\n",
    "for i, trigram in enumerate(trigram_result):\n",
    "    for k, v in iter(trigram.items()):\n",
    "        output_feature.at[i,k] += v\n",
    "\n",
    "output_feature.to_csv('output_encode.csv', index=False, header=False)\n",
    "\n",
    "food_df = pd.DataFrame(foods)\n",
    "service_df = pd.DataFrame(services)\n",
    "price_df = pd.DataFrame(prices)\n",
    "place_df = pd.DataFrame(places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keziasuhendra/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy food 0.678173719376392\n",
      "Best Param food {'n_estimators': 300, 'min_samples_leaf': 3, 'max_features': 0.25}\n",
      "[0.67032967 0.56043956 0.71428571 0.72527473 0.71111111 0.68888889\n",
      " 0.64444444 0.72727273 0.68181818 0.73863636]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def randomForest_fit(x_train, y_train, aspect, scoring = 'accuracy'):\n",
    "    randomForest = RandomForestClassifier(random_state=123)\n",
    "\n",
    "    hyperparam = {'min_samples_leaf': [3, 5, 7, 9, 13, 17, 21, 27, 33, 41, 50, 60, 80, 100],\n",
    "                  'max_features': ['sqrt', 'log2', 0.25, 0.5, 0.75], \n",
    "                  'n_estimators': [100, 200, 300, 500, 1000]}\n",
    "    \n",
    "    random_randomForest = RandomizedSearchCV(randomForest, param_distributions = hyperparam, cv = 5, \n",
    "                                           n_iter = 10, scoring = scoring, n_jobs=-1, random_state = 123)\n",
    "    random_randomForest.fit(x_train, y_train)\n",
    "    \n",
    "    print (\"Best Accuracy \" + aspect, random_randomForest.best_score_)\n",
    "    print (\"Best Param \" + aspect, random_randomForest.best_params_)\n",
    "    return random_randomForest\n",
    "\n",
    "# food\n",
    "best_randForest_food = randomForest_fit(output_feature, food_df.values.ravel(), \"food\")\n",
    "\n",
    "randForest_food = RandomForestClassifier(random_state=123, n_jobs = -1,\n",
    "                                   min_samples_leaf = best_randForest_food.best_params_.get('min_samples_leaf'),\n",
    "                                   max_features = best_randForest_food.best_params_.get('max_features'),\n",
    "                                   n_estimators = best_randForest_food.best_params_.get('n_estimators'))\n",
    "randForest_food.fit(output_feature, food_df.values.ravel())\n",
    "\n",
    "joblib.dump(randForest_food,'rf_food.pkl')\n",
    "\n",
    "print(cross_val_score(randForest_food, output_feature, food_df.values.ravel(), cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy price 0.9621380846325167\n",
      "Best Param price {'n_estimators': 300, 'min_samples_leaf': 3, 'max_features': 0.25}\n",
      "[0.96132597 0.9558011  0.96089385 0.96089385 0.97191011]\n"
     ]
    }
   ],
   "source": [
    "# price\n",
    "best_randForest_price = randomForest_fit(output_feature, price_df.values.ravel(), \"price\")\n",
    "\n",
    "randForest_price = RandomForestClassifier(random_state=123, n_jobs = -1,\n",
    "                                   min_samples_leaf = best_randForest_price.best_params_.get('min_samples_leaf'),\n",
    "                                   max_features = best_randForest_price.best_params_.get('max_features'),\n",
    "                                   n_estimators = best_randForest_price.best_params_.get('n_estimators'))\n",
    "randForest_price.fit(output_feature, price_df.values.ravel())\n",
    "\n",
    "joblib.dump(randForest_price,'rf_price.pkl')\n",
    "\n",
    "print(cross_val_score(randForest_price, output_feature, price_df.values.ravel(), cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy place 0.8507795100222717\n",
      "Best Param place {'n_estimators': 300, 'min_samples_leaf': 3, 'max_features': 0.25}\n",
      "[0.82417582 0.82417582 0.86813187 0.82417582 0.86666667 0.74444444\n",
      " 0.87640449 0.86516854 0.86363636 0.86363636]\n"
     ]
    }
   ],
   "source": [
    "# place\n",
    "best_randForest_place = randomForest_fit(output_feature, place_df.values.ravel(), \"place\")\n",
    "\n",
    "randForest_place = RandomForestClassifier(random_state=123, n_jobs = -1,\n",
    "                                   min_samples_leaf = best_randForest_place.best_params_.get('min_samples_leaf'),\n",
    "                                   max_features = best_randForest_place.best_params_.get('max_features'),\n",
    "                                   n_estimators = best_randForest_place.best_params_.get('n_estimators'))\n",
    "randForest_place.fit(output_feature, place_df.values.ravel())\n",
    "\n",
    "joblib.dump(randForest_place,'rf_place.pkl')\n",
    "\n",
    "print(cross_val_score(randForest_place, output_feature, place_df.values.ravel(), cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy service 0.8708240534521158\n",
      "Best Param service {'n_estimators': 300, 'min_samples_leaf': 3, 'max_features': 0.25}\n",
      "[0.84782609 0.84615385 0.87777778 0.85555556 0.87777778 0.84269663\n",
      " 0.88764045 0.8988764  0.88764045 0.92134831]\n"
     ]
    }
   ],
   "source": [
    "# service\n",
    "best_randForest_service = randomForest_fit(output_feature, service_df.values.ravel(), \"service\")\n",
    "\n",
    "randForest_service = RandomForestClassifier(random_state=123, n_jobs = -1,\n",
    "                                   min_samples_leaf = best_randForest_service.best_params_.get('min_samples_leaf'),\n",
    "                                   max_features = best_randForest_service.best_params_.get('max_features'),\n",
    "                                   n_estimators = best_randForest_service.best_params_.get('n_estimators'))\n",
    "randForest_service.fit(output_feature, service_df.values.ravel())\n",
    "\n",
    "joblib.dump(randForest_service,'rf_service.pkl')\n",
    "\n",
    "print(cross_val_score(randForest_service, output_feature, service_df.values.ravel(), cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00275019 0.99724981 0.        ]]\n",
      "neutral\n",
      "[[0.0117383  0.96775647 0.02050523]]\n",
      "neutral\n",
      "[[5.48027490e-03 9.94349353e-01 1.70371624e-04]]\n",
      "neutral\n",
      "[[0.06906133 0.8988769  0.03206176]]\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "randForest_food = joblib.load('rf_food.pkl')\n",
    "randForest_price = joblib.load('rf_price.pkl')\n",
    "randForest_place = joblib.load('rf_place.pkl')\n",
    "randForest_service = joblib.load('rf_service.pkl')\n",
    "\n",
    "def predictData(classifier, datas, aspect):\n",
    "    tokenize_data = []\n",
    "    filtered_data = []\n",
    "    for review in datas:\n",
    "        data_tokens = word_tokenize(review)\n",
    "        tokenize_data.append(data_tokens)\n",
    "    \n",
    "    for review in tokenize_data:\n",
    "        review = RemovePunctAndStopWords(review)\n",
    "        filtered_data.append(review)\n",
    "    \n",
    "    data_result = []\n",
    "    for i in range(len(filtered_data)):\n",
    "        data = ngram_list(filtered_data[i], 1)\n",
    "        data_result.append(data)\n",
    "\n",
    "    feature = []\n",
    "    for trigram in trigram_set:\n",
    "        feature.append(data_result[0].count(trigram) if trigram in data_result[0] else 0)\n",
    "                \n",
    "    output_data = pd.DataFrame(feature)\n",
    "    output_data.to_csv('output_data.csv', index=False, header=False)\n",
    "    \n",
    "    result = classifier.predict(output_data.T)\n",
    "    result_proba = classifier.predict_proba(output_data.T)\n",
    "    print(result_proba)\n",
    "    if result > 0:\n",
    "        return('positive')\n",
    "    elif result < 0:\n",
    "        return('negative')\n",
    "    else:\n",
    "        return('neutral')\n",
    "\n",
    "text = [\"Call me nitpicky, but overcooked yolks pretty much kills the dish.\"]\n",
    "\n",
    "print(predictData(randForest_price, text, \"price\"))\n",
    "print(predictData(randForest_place, text, \"place\"))\n",
    "print(predictData(randForest_service, text, \"service\"))\n",
    "print(predictData(randForest_food, text, \"food\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0790997  0.89466953 0.02623077]]\n",
      "neutral\n",
      "[[0.00238987 0.99761013 0.        ]]\n",
      "neutral\n",
      "[[0.04808667 0.92676086 0.02515247]]\n",
      "neutral\n",
      "[[5.90811632e-02 9.40748465e-01 1.70371624e-04]]\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "def predictData(datas, aspect):\n",
    "    classifier = joblib.load('rf_food.pkl')\n",
    "    if (aspect == \"price\"):\n",
    "        classifier = joblib.load('rf_price.pkl')\n",
    "    if (aspect == \"place\"):\n",
    "        classifier = joblib.load('rf_place.pkl')\n",
    "    if (aspect == \"service\"):\n",
    "        classifier = joblib.load('rf_service.pkl')\n",
    "    \n",
    "    tokenize_data = []\n",
    "    filtered_data = []\n",
    "    for review in datas:\n",
    "        data_tokens = word_tokenize(review)\n",
    "        tokenize_data.append(data_tokens)\n",
    "    \n",
    "    for review in tokenize_data:\n",
    "        review = RemovePunctAndStopWords(review)\n",
    "        filtered_data.append(review)\n",
    "    \n",
    "    data_result = []\n",
    "    for i in range(len(filtered_data)):\n",
    "        data = ngram_list(filtered_data[i], 1)\n",
    "        data_result.append(data)\n",
    "        \n",
    "#     print(trigram_set)\n",
    "\n",
    "    feature = []\n",
    "    for trigram in trigram_set:\n",
    "        feature.append(data_result[0].count(trigram) if trigram in data_result[0] else 0)\n",
    "                \n",
    "    output_data = pd.DataFrame(feature)\n",
    "    output_data.to_csv('output_data.csv', index=False, header=False)\n",
    "    \n",
    "    result = classifier.predict(output_data.T)\n",
    "    result_proba = classifier.predict_proba(output_data.T)\n",
    "    print(result_proba)\n",
    "    if result > 0:\n",
    "        return('positive')\n",
    "    elif result < 0:\n",
    "        return('negative')\n",
    "    else:\n",
    "        return('neutral')\n",
    "    \n",
    "    \n",
    "text = [\"The breakfast is great here and staff are very friendly.\"]\n",
    "\n",
    "print(predictData(text, \"food\"))\n",
    "print(predictData(text, \"price\"))\n",
    "print(predictData(text, \"place\"))\n",
    "print(predictData(text, \"service\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
